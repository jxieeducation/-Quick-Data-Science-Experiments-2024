{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94bedd43-ac56-4c06-a1fc-5f413ca30888",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Simple dataset: sequence of characters\n",
    "data = \"hello world\"\n",
    "chars = list(set(data))\n",
    "char_to_idx = {ch: i for i, ch in enumerate(chars)}\n",
    "idx_to_char = {i: ch for i, ch in enumerate(chars)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4da264db-3eb7-4b4f-99c1-08782c1103d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'d': 0, 'l': 1, 'h': 2, ' ': 3, 'e': 4, 'o': 5, 'w': 6, 'r': 7}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8b4ec9e-2171-4312-8720-3c6715549d1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'd', 1: 'l', 2: 'h', 3: ' ', 4: 'e', 5: 'o', 6: 'w', 7: 'r'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_to_char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0af64294-b064-4dc0-b390-49fcda9fc098",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(sequence, n_chars):\n",
    "    encoding = torch.zeros(len(sequence), n_chars)\n",
    "    # print(\"test\")\n",
    "    # print(encoding.shape)\n",
    "    for i, char in enumerate(sequence):\n",
    "        encoding[i][char_to_idx[char]] = 1\n",
    "    return encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "497f125b-faef-4b38-abc4-bdf6067eb2c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "        [0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_size = len(chars)\n",
    "one_hot_encode(data, input_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3f2f6a19-4893-43b5-9e7d-84ba36b7bf67",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(SimpleRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        out, hidden = self.rnn(x, hidden)\n",
    "        out = self.fc(out)\n",
    "        return out, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3461eb1b-047a-4cf6-b4eb-9f47117069fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10, 8])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_encode(data[:-1], input_size).shape\n",
    "one_hot_encode(data[:-1], input_size).unsqueeze(0).shape\n",
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "42e20944-c20b-48e5-897e-354331b0d7fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 2.095881462097168\n",
      "Epoch 2, Loss: 2.0332283973693848\n",
      "Epoch 3, Loss: 1.9832065105438232\n",
      "Epoch 4, Loss: 1.9388881921768188\n",
      "Epoch 5, Loss: 1.899026870727539\n",
      "Epoch 6, Loss: 1.86286199092865\n",
      "Epoch 7, Loss: 1.8301136493682861\n",
      "Epoch 8, Loss: 1.8008530139923096\n",
      "Epoch 9, Loss: 1.7751657962799072\n",
      "Epoch 10, Loss: 1.7522751092910767\n"
     ]
    }
   ],
   "source": [
    "input_size = len(chars)\n",
    "hidden_size = 12\n",
    "output_size = len(chars)\n",
    "model = SimpleRNN(input_size, hidden_size, output_size)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Training loop\n",
    "hidden = None\n",
    "for epoch in range(10):\n",
    "    optimizer.zero_grad()\n",
    "    input_seq = one_hot_encode(data[:-1], input_size).unsqueeze(0)\n",
    "    target_seq = torch.tensor([char_to_idx[ch] for ch in data[1:]])\n",
    "    output, hidden = model(input_seq, hidden)\n",
    "    loss = criterion(output.view(-1, output_size), target_seq)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    hidden = hidden.detach()\n",
    "    print(f'Epoch {epoch+1}, Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "48bcf831-a091-473f-b873-51af251a1a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class SimpleTransformer(nn.Module):\n",
    "    def __init__(self, input_dim, model_dim, nhead, num_encoder_layers, num_decoder_layers, output_dim):\n",
    "        super(SimpleTransformer, self).__init__()\n",
    "        self.encoder = nn.Embedding(input_dim, model_dim)\n",
    "        self.transformer = nn.Transformer(model_dim, nhead, num_encoder_layers, num_decoder_layers)\n",
    "        self.decoder = nn.Linear(model_dim, output_dim)\n",
    "\n",
    "    def forward(self, src, tgt):\n",
    "        src = self.encoder(src)\n",
    "        tgt = self.encoder(tgt)\n",
    "        output = self.transformer(src, tgt)\n",
    "        output = self.decoder(output)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9d92683a-b611-47cc-bd5c-1cd5ee3ce331",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.12/site-packages/torch/nn/modules/transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    }
   ],
   "source": [
    "input_dim = 1000\n",
    "model_dim = 512\n",
    "nhead = 8\n",
    "num_encoder_layers = 3\n",
    "num_decoder_layers = 3\n",
    "output_dim = 1000\n",
    "\n",
    "model = SimpleTransformer(input_dim, model_dim, nhead, num_encoder_layers, num_decoder_layers, output_dim)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "94490c1c-f5ad-449d-a049-6d65389f52e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 23.506019592285156\n",
      "Epoch 2, Loss: 20.867658615112305\n",
      "Epoch 3, Loss: 17.07345199584961\n",
      "Epoch 4, Loss: 12.046655654907227\n",
      "Epoch 5, Loss: 6.62406063079834\n",
      "Epoch 6, Loss: 7.386845588684082\n",
      "Epoch 7, Loss: 8.1568021774292\n",
      "Epoch 8, Loss: 8.26572036743164\n",
      "Epoch 9, Loss: 7.5390119552612305\n",
      "Epoch 10, Loss: 6.645153045654297\n"
     ]
    }
   ],
   "source": [
    "src = torch.randint(0, input_dim, (10, 32))\n",
    "tgt = torch.randint(0, input_dim, (10, 32))\n",
    "tgt_output = torch.randint(0, output_dim, (10, 32))\n",
    "\n",
    "for epoch in range(10):\n",
    "    optimizer.zero_grad()\n",
    "    output = model(src, tgt)\n",
    "    loss = criterion(output.view(-1, output_dim), tgt_output.view(-1))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(f'Epoch {epoch+1}, Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0e45ec-168a-4d70-aad5-a54b6bf32a3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
