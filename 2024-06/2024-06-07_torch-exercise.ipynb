{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af0700b9-3707-42a3-a0e5-917e7e3001a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "  'Characterizes a dataset for PyTorch'\n",
    "  def __init__(self, list_IDs, labels):\n",
    "        'Initialization'\n",
    "        self.labels = labels\n",
    "        self.list_IDs = list_IDs\n",
    "\n",
    "  def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        return len(self.list_IDs)\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "        'Generates one sample of data'\n",
    "        # Select sample\n",
    "        ID = self.list_IDs[index]\n",
    "\n",
    "        # Load data and get label\n",
    "        X = torch.load('data/' + ID + '.pt')\n",
    "        y = self.labels[ID]\n",
    "\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc5a01db-c214-494c-88ae-ba3e4dd330c6",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3238555980.py, line 17)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[2], line 17\u001b[0;36m\u001b[0m\n\u001b[0;31m    partition = # IDs\u001b[0m\n\u001b[0m                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from my_classes import Dataset\n",
    "\n",
    "\n",
    "# CUDA for PyTorch\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "# Parameters\n",
    "params = {'batch_size': 64,\n",
    "          'shuffle': True,\n",
    "          'num_workers': 6}\n",
    "max_epochs = 100\n",
    "\n",
    "# Datasets\n",
    "partition = # IDs\n",
    "labels = # Labels\n",
    "\n",
    "# Generators\n",
    "training_set = Dataset(partition['train'], labels)\n",
    "training_generator = torch.utils.data.DataLoader(training_set, **params)\n",
    "\n",
    "validation_set = Dataset(partition['validation'], labels)\n",
    "validation_generator = torch.utils.data.DataLoader(validation_set, **params)\n",
    "\n",
    "# Loop over epochs\n",
    "for epoch in range(max_epochs):\n",
    "    # Training\n",
    "    for local_batch, local_labels in training_generator:\n",
    "        # Transfer to GPU\n",
    "        local_batch, local_labels = local_batch.to(device), local_labels.to(device)\n",
    "\n",
    "        # Model computations\n",
    "        [...]\n",
    "\n",
    "    # Validation\n",
    "    with torch.set_grad_enabled(False):\n",
    "        for local_batch, local_labels in validation_generator:\n",
    "            # Transfer to GPU\n",
    "            local_batch, local_labels = local_batch.to(device), local_labels.to(device)\n",
    "\n",
    "            # Model computations\n",
    "            [...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1c9f58-e695-4864-a097-3df8adc3eead",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61f27935-a6de-4b89-bfe8-f05b8b57463d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, models, transforms\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "## print out the pytorch version used (1.31 at the time of this tutorial)\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba8c2e4e-af83-431c-a2f4-f4b145737483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print (device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33140622-4c82-4e15-bd37-22fb198dfa62",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m drive\n\u001b[1;32m      2\u001b[0m drive\u001b[38;5;241m.\u001b[39mmount(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgdrive\u001b[39m\u001b[38;5;124m'\u001b[39m, force_remount\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google'"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('gdrive', force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ccad7e5-55ed-4e24-8e4c-d7bf5eeafd18",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LR(nn.Module):\n",
    "    def __init__(self, dim, lr=torch.scalar_tensor(0.01)):\n",
    "        super(LR, self).__init__()\n",
    "        # intialize parameters\n",
    "        self.w = torch.zeros(dim, 1, dtype=torch.float).to(device)\n",
    "        self.b = torch.scalar_tensor(0).to(device)\n",
    "        self.grads = {\"dw\": torch.zeros(dim, 1, dtype=torch.float).to(device),\n",
    "                      \"db\": torch.scalar_tensor(0).to(device)}\n",
    "        self.lr = lr.to(device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        ## compute forward\n",
    "        z = torch.mm(self.w.T, x)\n",
    "        a = self.sigmoid(z)\n",
    "        return a\n",
    "\n",
    "    def sigmoid(self, z):\n",
    "        return 1/(1 + torch.exp(-z))\n",
    "\n",
    "    def backward(self, x, yhat, y):\n",
    "        ## compute backward\n",
    "        self.grads[\"dw\"] = (1/x.shape[1]) * torch.mm(x, (yhat - y).T)\n",
    "        self.grads[\"db\"] = (1/x.shape[1]) * torch.sum(yhat - y)\n",
    "    \n",
    "    def optimize(self):\n",
    "        ## optimization step\n",
    "        self.w = self.w - self.lr * self.grads[\"dw\"]\n",
    "        self.b = self.b - self.lr * self.grads[\"db\"]\n",
    "\n",
    "def loss(yhat, y):\n",
    "    m = y.size()[1]\n",
    "    return -(1/m)* torch.sum(y*torch.log(yhat) + (1 - y)* torch.log(1-yhat))\n",
    "\n",
    "def predict(yhat, y):\n",
    "    y_prediction = torch.zeros(1, y.size()[1])\n",
    "    for i in range(yhat.size()[1]):\n",
    "        if yhat[0, i] <= 0.5:\n",
    "            y_prediction[0, i] = 0\n",
    "        else:\n",
    "            y_prediction[0, i] = 1\n",
    "    return 100 - torch.mean(torch.abs(y_prediction - y)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e023a7-aaf8-4e95-abba-e6216b1e6ff1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
